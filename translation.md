#### DeepMB: Глубокая нейронная сеть для генераций оптоакустических изображений в реальном времени с регулируемой скорстью звука
Кристофер Денер$^{1, 2, *}$, Гийом Занд$^{1, 3, *}$, Василис Нтизахристос$^{1, 2, 4, +}$, Доминик Юстель$^{1, 2, 5, +}$

$^1$*Институт Биологической и Медицинской Визуализации, Центр Гельмгольца в Мюнхене, Нойхерберг, Германия*  
$^2$*Кафедра Биологической Визуализации в Центральном Институте Трансляционных Исследований Рака (TranslaTUM), Школа Медицины, Технический Униферситет Мюнхена, Германия*  
$^3$*iThera Medical GambH, Мюнхен, Германия*  
$^4$*Мюнхенский Институт Робототехники и Машинного Интелекта, Технический Университет Мюнхена, Германия*  
$^5$*Институт Вычислительной Биологии, Центр Гельмгольца в Мюнхене, Нойхерберг, Германия*  

$^*$*Эти авторы внесли равный вклад в данную работу.*  
$^+$*Эти авторы разделяют соответствующее авторство.*

> Для перевода термина 'image reconstruction' я начал использовать термин 'генерация изображений', но позже понял, что термин 'восстановление изображений' больше подходит по смыслу, так как термин
> 'генерация' в статье исползуется для описания процесса создания искуственных тестовых данных.  
> В этом переводе, для постоянства, я продолжу использовать термин 'генерация изображений', но для выполнения заданий заменю его на термин 'восстановление изображений'.

**Аннотация**: Мультиспектральная оптоакустическая томография (МСОТ) это метод функциональной визуализации в высоком разрешении, которая имеет возможность неинвазивного (без физического проникновения через 
естественные внешние барьеры организма) доступа к широкому диапазону патофизиологических (нарушающих жизнедеятельность организма) явлений посредством качественной оценки контраста эндогенных (содержаться в 
тканях в естественном состоянии) хромофор (вещества, придающие окраску тканям) в ткани. Визуальизация в реальном времени необходима чтобы перевести МСОТ в клиническую визуализацию, визуализировать динамические 
патофизиологические измениения связанные с прогрессирвоанием болезней, и позволяют непосредственно производить диагностику. Генерация на основе моделей представляет собой новейшую технологию оптоакустической 
визуализации; однако, продвинутое качество изображений, предоставляемое генерацией на основе моделей остается недоступной для визуализации в реальном времени, так как алгоритм является итеративным и, 
соответственно, вычислительно затратным. Глубокое обучение предоставляет более быструю генерацию оптоакустических изображений, но недостаток действительных экспериментальных данных для обучения может привести 
к ухудшению качества визуализации для естественных экспериментальных данных. В данной работе мы добиваемся точной генерации оптоакустических изображений для произвольных (экспериментальных) входных данных за 
31 мс на одно изображение посредством выражения генерации на основе моделей с использованием глуоких нейронных сетей. Предоставленная структура глубокого обучения, названная DeepMB, способствует точному 
обобщению синтетических тренировочных данных к экспериментальным тестовым данным через обучение на оптоакустических сигналах, синтезированных из реальных изображений и действительных оптоакустических изображений,
сгенерированных с помощью генерации на основе моделей. Данная структура предоставляет сфокусированные сзображения для широкого диапазона частей тела с различными параметрами аккустической проницаемости, так как 
данная структура поддерживает динамическую регулировку генерируемой скорости звука для визуализации. Более того, DeepMB сравнима по скорости передачи данных и размеру изображений с современными 
мультиспектральными оптоакустическими томографами, вследствии чего имеет возможность прямого применения в клинической практике. Мы провели как качественные, так и количественные оценки DeepMB на разнообразных 
наборах данных естественных изображений, и показали, что структура генерирует изображения примерно в 1000 раз быстрее по сравнению с итеративной генерацией на основе моделей, в то же время предоставляя 
практически идентичное качество изображений. Точность и скорость генерации изображений с использованием DeepMB может предоставить широкий доступ к высокому качесву и мультиспектральной контрастности портативной 
оптоакустической томографии глубоких тканей, вследствии чего облегчит работу с продвинутыми приложениями динамической визуализации.

#### 1. Введение
Мультиспектральная оптоакустическая томография (МСОТ) это развивающийся метод функциональной визуализации, который дает уникальную возможность неинвазивного обнаружения оптического контраста в высоком 
пространственном разрешени и сантиметровом проникновении внутрь живых тканей. Получая доступ к мультиспектрильному контрасту эндогенных хромофор, МСОТ может количественно оценить широкий диапазон 
патофизиологических суррогатных биомаркеров, таких как фибозис тканей, воспаления, вазикуляция и оксигенация, и предоставляют уникальную клиническую информацию о таких заболеваниях, как рак груди, мышечная 
дисрофия Дюшена, или восполительные заболевания кишечника.

Для того, чтобы полностью перевести и интегрировать МСОТ в клиническую визуализацию, необходимы приложения реального времени. Портативная визуализация МСОТ требует &mdash; в той же степени что и ультразвуковая 
визуализация &mdash; обратную связь с изображением в реальном времени с достаточно высокой частотой кадров (как минимум 24 кадра в секунду при полной обработке видео) чтобы избежать затруднение зрительно-тактильной 
координации, определить и локализовать соответствующие структуры тканей, используя части тела в их окружении, и найти оптимальное положение датчика для целевой области. Помимо этого, оптоакустическая 
визуализация в реальном времени необходима, чтобы визуализировать динамические патофизиологические изменени, связанные с прогрессированием заболеваний и позволяет осуществлять наведение и диагностику на месте 
во время интераоперационного вмешательства и эндоскопической визуализации (визуализации внутренних органов без операции). На практике, генерация оптоакустических изображений в реальном времени (то есть 
восстановление исходного распределения давления в изображаемой ткани) обычно проводится с использованием алгоритма обратной проекции. Однако, формула обратной проекции основана на чрезмерно упрощенных 
предположениях о моделировании процесса визуализации и не может компенсировать нечеткость исходной задачи инверсс, возникающей из-за ограниченного угла съемки, шумов измерений и конечной полосы пропускания 
датчика. Следовательно, изображения обратной проекции систематически страдают от низкого пространственного разрешения и контраста, а также отрицательных значений пикселей, которые делают невозможной физическую 
интерпретацию изображений как исходное распределение давления. В противовес этому, итеративная реконструкция на основе моделей может предоставить точные оптоакустические изображения с наилучшим качесвом, 
посредством вклучения физической модели визуализирующего устройства в процесс генерации, ограничевая неотрицательность генерируемого изображения, и внедряя регуляризацию чтобы смягчить нечеткость задачи инверсии. 
Однако, генерация на основе моделей вычислительно затратен из-за итерационного, и, следовательно, последовательного характера алгоритма, что не позволяет использовать его для визуализации в реальном времени. 
Генерация на основе моделей в реальном времени была продемонстрирована для пре-клинических МСОТ систем посредством произведения вычислений для генерации на графическом процессоре. Однако, подобное ускорение 
неприменимо для наиболее качественной генерации на основе моделей на данных из современных клинических систем, так как эти генерации значительно более вычислительно требовательны (изображения больше, более 
сложный функционал обобщения, включение в модель полеого импульсного отклика системы, необходимость большего числа итераций для сходимости). Таким образом, полный потенциал визуализации МСОТ доступен только 
после значительного вычислительного времени и в данный момент остается недоступен для клинического приложени, которое требует живого визуального отклика.

> ... другую половину переведу после перевода процесса разработки

#### 2. Результаты
Чтобы подтвердить возможность DeepMB генерировать изображения в реальном времени с возможностью регулировки скорости звука, структура была применена к современному портативному оптоакустическому сканеру
(МСОТ Acuity Echo, iThera, Medical GambH, Мюнхен, Германия) со значениями скоростей звука в диапазоне от 1475 м/с до 1525 м/с с шагом 5 м/с.

##### Процесс разработки DeepMB
На рисунке 1 изображен общий процесс обучения и оценки. DeepMB был обучен, аналогично структуре AUTOMAP, используя входные синограммы, синтезированные из изображений общего вида, чтобы облегчить обучение
беспрестрастному и универсально применимому оператору генераций. Синограммы были сгенерированны путем использования сборника разнообразных изображений реального мира, находящихся в открытом доступе, в качестве 
исходных распределений давления и симулирования на их основе сигналов, записаных с помощью аккустических преобразователей с точной физической моделью рассматриваемого сканера (рисунок 1a и раздел "Методы / Синтез 
синограм для обучения и проверки"). Значения скорости звука для дальнейших симуляций были взяты равномерно случайным образоми (имеется в виду с равномерным распределением) из рассматриваемого диапазона для каждого изображения. Действилельные изображения для 
синтезированных синограм были вычесленны с помощью генераций на основе моделей (рисунок 1с). Рисунок 1d показывает архитекуру глубокой нейронной сети DeepMB, которая получает на вход синограму (или синтетическую, 
или естественную) и значение скорости звука и возвращает итоговое сгенерированное изображение. Основной дизайн основан на архитектуре U-Net, дополненной парой расширений, которые позволяют сети обучаться и 
выражать эффект различных входных значений скорости звука на генерируемое изображение: (1) все сигналы были отображены из входных синограм на область изображения с помощью оператора линейной задержки на основе 
данной на вход величины скорости звука (без обучаемых весов), и (2) входное значение скорости звука (единовременно закодированное и добавленное как дополнительный канал) было передано обучаемым конволюционным 
(конволюция - математический процесс вычисления взвешенного среднего квадратичной матрицы, центром которой проследовательно является каждая точка в изображении) слоям сети. Подробное описание обучения сети дано
в разделе "Методы / Обучение сети". После обучения, приложение DeepMB к клиническим данным было протестировано с разнообразным набором данных естественных синограмм, полученных путем сканирования шести участников 
в не более чем восьми частях тела у каждого (рисунок 1b). Соответствующие достоверные изображения полученных естественных тестовых синограм были получены аналогично тренеровочным данным используя генерацию на 
основе моделей. Вывод DeepMB составил 31 мс на образец на современном видеопроцессоре (NVIDIA GeForce RTX 3090).

![Изображение полного процесса разработки](https://sun9-62.userapi.com/impg/wDTP6sd4DKcW8clCRyYOAmvpQ73nT9lXWzBx2w/0ov_V9psDec.jpg?size=763x405&quality=96&sign=cedda79369589519d83b466667a9c028&type=album)  
<em>
Рисунок 1: Процесс разработки DeepMB. (a) Изображения реального мира, полученные из общественно доступного набора данных, используются чтобы сгенерировать синтетические синограмы путем применения точной 
физической прямой модели сканера. SoS, скорость звука. (b) Естественные синограмы были получены из различных частей тела шести участников. \(c\) Оптоакустические изображения генерируются с помощью итеративной 
реконструкции на основе моделей с целью генерации контрольных изображений для синтетического набора данных (A) или естественного набора данных (B). (d) Обучение сети проведено с использованием синтетических 
данных как набора для тренировки (n = 8000) и проверки (n = 2000) (С), в то время как естественные данные используются как набор тестов (n = 4814) (D). Преобразование доменов сначала применяется к входным 
синограмам с помощью операции задержки чтобы отобразить значения из выборки времени на область изображения. Скорость звука определяется единовременно и добавляется как отдельные каналы (отображено как символ "⧺"). 
Конволюционная нейронная сеть U-Net впоследствии применяется к стеку каналов чтобы регрессировать конечное изображение. Различие вычисляется между выводом сети и соответствующим контрольным изображением (смотрите 
раздел "Методы / Обучение сети" для дальнейшей информации касательно обечения сети).
</em>

> Эти разделы из методов я перевел, так как на них были ссылки в разделе процесса разработки

#### 4. Методы

##### Синтез синограм для обучения и проверки
Для обучения и проверки, оптоакустические синограмы были синтезированы с помощью точной физической прямой модели процесса визуализации, который включает в себя полную импульсную характеристику системы, 
использующцю величину скорости звука как параметр, взятый равномерно случайным образом из диапазона 1475-1525 м/с с шагом 5 м/c. Изображения реального мира, использованные в качестве начального распределения 
давления для дальнейшей симуляции, были случайно выбираны из общественно доступного набора данных PASCAL Visual Object Classes Challenge 2012 (VOC2012), и преобразованы в одноканальные черно-белые изображения 
с разрешением 416 на 416 пикселей. После применения прямой модели, каждая синтезированная синограма была масштабирована на коэффициент, выбранный равномерно случайным образом из диапазона 0-450 для лучшего 
соответствия дисперсии, наблюдаемой  на синограммах в естественных условиях.

##### Обучение сети
Сеть DeepMB была реализована на языке программирования Python с исползованием PyTorch. Она была обучена &mdash; или на синтезированных или на естественных данных &mdash; в течение 300 поколений используя 
[стохастический градиентный спуск](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA) 
с размером партии равном 4, скорости обучения равной 0.01, импульсом равном 0.99, и коэффициентом затухания скорости обучения равном 0.99. Потеря сети была вычислена как среднее квадратическое откланение между 
выходным изображением и контрольным изображением. Итоговая модель была выбрана на основе минимальной потери на проверочном наборе данных, и наконец скомпилирована в ONNX модел для ускорения.

Для облегчения обучения, все входные синогрмы были масштабированны на $K=450^{-1}$ чтобы убедиться что ни одно значение не выйдет из диапазона \[-1, 1\]. Идентичный коэффициент масштабирования также был применен 
ко всем целевым изображениям. Более того, квадратный корень был применен ко всем целевым контрольным изображениям, используемым в процессе обучения и проверки, чтобы редуцировать выходные значения сети и 
ограничить влияние пикселей с высокой интенсивностью в процессе вычисления потери. Когда обученная сеть применяется к естественным данным, предполагаемые изображения (имеется в виду те, что выдала нейронка),
сначала были возведены в квадрат и масштабированы на $K^{-1}$, чтобы отменить операции обработки.

> ![](https://sun9-28.userapi.com/c237231/u138836881/docs/d30/e7ec47891042/ezgif-5-f0bd9115e8.gif?extra=PNWH_NRyUs31i7qRBxWJ_kJzXIBoztmhgofIsIpiYIWeULMDUmRP9hyC88eBtgz83-WknJM3O2gaYpIdjFK3kcpcQaaZ_dycr1Xt8ta_GgAD2l9quSwfe2vwI-9uvUsC9tzUzWQQLcIol6UgNF5e8Jymtg)

