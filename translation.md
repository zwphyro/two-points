#### DeepMB: Глубокая нейронная сеть для генераций оптоакустических изображений в реальном времени с регулируемой скорстью звука
Кристофер Денер$^{1, 2, *}$, Гийом Занд$^{1, 3, *}$, Василис Нтизахристос$^{1, 2, 4, +}$, Доминик Юстель$^{1, 2, 5, +}$

$^1$*Институт Биологической и Медицинской Визуализации, Центр Гельмгольца в Мюнхене, Нойхерберг, Германия*  
$^2$*Кафедра Биологической Визуализации в Центральном Институте Трансляционных Исследований Рака (TranslaTUM), Школа Медицины, Технический Униферситет Мюнхена, Германия*  
$^3$*iThera Medical GambH, Мюнхен, Германия*  
$^4$*Мюнхенский Институт Робототехники и Машинного Интелекта, Технический Университет Мюнхена, Германия*  
$^5$*Институт Вычислительной Биологии, Центр Гельмгольца в Мюнхене, Нойхерберг, Германия*  

$^*$*Эти авторы внесли равный вклад в данную работу.*  
$^+$*Эти авторы разделяют соответствующее авторство.*

> Для перевода термина 'image reconstruction' я начал использовать термин 'генерация изображений', но позже понял, что термин 'восстановление изображений' больше подходит по смыслу, так как термин
> 'генерация' в статье исползуется для описания процесса создания искуственных тестовых данных.  
> В этом переводе, для постоянства, я продолжу использовать термин 'генерация изображений', но для выполнения заданий заменю его на термин 'восстановление изображений'.

**Аннотация**: Мультиспектральная оптоакустическая томография (МСОТ) это метод функциональной визуализации в высоком разрешении, которая имеет возможность неинвазивного (без физического проникновения через 
естественные внешние барьеры организма) доступа к широкому диапазону патофизиологических (нарушающих жизнедеятельность организма) явлений посредством качественной оценки контраста эндогенных (содержаться в 
тканях в естественном состоянии) хромофор (вещества, придающие окраску тканям) в ткани. Визуальизация в реальном времени необходима чтобы перевести МСОТ в клиническую визуализацию, визуализировать динамические 
патофизиологические измениения связанные с прогрессирвоанием болезней, и позволяют непосредственно производить диагностику. Генерация на основе моделей представляет собой новейшую технологию оптоакустической 
визуализации; однако, продвинутое качество изображений, предоставляемое генерацией на основе моделей остается недоступной для визуализации в реальном времени, так как алгоритм является итеративным и, 
соответственно, вычислительно затратным. Глубокое обучение предоставляет более быструю генерацию оптоакустических изображений, но недостаток действительных экспериментальных данных для обучения может привести 
к ухудшению качества визуализации для естественных экспериментальных данных. В данной работе мы добиваемся точной генерации оптоакустических изображений для произвольных (экспериментальных) входных данных за 
31 мс на одно изображение посредством выражения генерации на основе моделей с использованием глуоких нейронных сетей. Предоставленная структура глубокого обучения, названная DeepMB, способствует точному 
обобщению синтетических тренировочных данных к экспериментальным тестовым данным через обучение на оптоакустических сигналах, синтезированных из реальных изображений и действительных оптоакустических изображений,
сгенерированных с помощью генерации на основе моделей. Данная структура предоставляет сфокусированные сзображения для широкого диапазона частей тела с различными параметрами аккустической проницаемости, так как 
данная структура поддерживает динамическую регулировку генерируемой скорости звука для визуализации. Более того, DeepMB сравнима по скорости передачи данных и размеру изображений с современными 
мультиспектральными оптоакустическими томографами, вследствии чего имеет возможность прямого применения в клинической практике. Мы провели как качественные, так и количественные оценки DeepMB на разнообразных 
наборах данных естественных изображений, и показали, что структура генерирует изображения примерно в 1000 раз быстрее по сравнению с итеративной генерацией на основе моделей, в то же время предоставляя 
практически идентичное качество изображений. Точность и скорость генерации изображений с использованием DeepMB может предоставить широкий доступ к высокому качесву и мультиспектральной контрастности портативной 
оптоакустической томографии глубоких тканей, вследствии чего облегчит работу с продвинутыми приложениями динамической визуализации.

#### 1. Введение
Мультиспектральная оптоакустическая томография (МСОТ) это развивающийся метод функциональной визуализации, который дает уникальную возможность неинвазивного обнаружения оптического контраста в высоком 
пространственном разрешени и сантиметровом проникновении внутрь живых тканей. Получая доступ к мультиспектрильному контрасту эндогенных хромофор, МСОТ может количественно оценить широкий диапазон 
патофизиологических суррогатных биомаркеров, таких как фибозис тканей, воспаления, вазикуляция и оксигенация, и предоставляют уникальную клиническую информацию о таких заболеваниях, как рак груди, мышечная 
дисрофия Дюшена, или восполительные заболевания кишечника.

Для того, чтобы полностью перевести и интегрировать МСОТ в клиническую визуализацию, необходимы приложения реального времени. Портативная визуализация МСОТ требует &mdash; в той же степени что и ультразвуковая 
визуализация &mdash; обратную связь с изображением в реальном времени с достаточно высокой частотой кадров (как минимум 24 кадра в секунду при полной обработке видео) чтобы избежать затруднение зрительно-тактильной 
координации, определить и локализовать соответствующие структуры тканей, используя части тела в их окружении, и найти оптимальное положение датчика для целевой области. Помимо этого, оптоакустическая 
визуализация в реальном времени необходима, чтобы визуализировать динамические патофизиологические изменени, связанные с прогрессированием заболеваний и позволяет осуществлять наведение и диагностику на месте 
во время интераоперационного вмешательства и эндоскопической визуализации (визуализации внутренних органов без операции). На практике, генерация оптоакустических изображений в реальном времени (то есть 
восстановление исходного распределения давления в изображаемой ткани) обычно проводится с использованием алгоритма обратной проекции. Однако, формула обратной проекции основана на чрезмерно упрощенных 
предположениях о моделировании процесса визуализации и не может компенсировать нечеткость исходной задачи инверсс, возникающей из-за ограниченного угла съемки, шумов измерений и конечной полосы пропускания 
датчика. Следовательно, изображения обратной проекции систематически страдают от низкого пространственного разрешения и контраста, а также отрицательных значений пикселей, которые делают невозможной физическую 
интерпретацию изображений как исходное распределение давления. В противовес этому, итеративная реконструкция на основе моделей может предоставить точные оптоакустические изображения с наилучшим качесвом, 
посредством вклучения физической модели визуализирующего устройства в процесс генерации, ограничевая неотрицательность генерируемого изображения, и внедряя регуляризацию чтобы смягчить нечеткость задачи инверсии. 
Однако, генерация на основе моделей вычислительно затратен из-за итерационного, и, следовательно, последовательного характера алгоритма, что не позволяет использовать его для визуализации в реальном времени. 
Генерация на основе моделей в реальном времени была продемонстрирована для пре-клинических МСОТ систем посредством произведения вычислений для генерации на графическом процессоре. Однако, подобное ускорение 
неприменимо для наиболее качественной генерации на основе моделей на данных из современных клинических систем, так как эти генерации значительно более вычислительно требовательны (изображения больше, более 
сложный функционал обобщения, включение в модель полеого импульсного отклика системы, необходимость большего числа итераций для сходимости). Таким образом, полный потенциал визуализации МСОТ доступен только 
после значительного вычислительного времени и в данный момент остается недоступен для клинического приложени, которое требует живого визуального отклика.

В последнее время глубокие нейронные сети успешно применяются для различных обратных задачах визуализации, используя их способность использовать подходящие обратные преобразования ориентируясь на данные для 
эффективного применения этих преобразований к новым данным. Генерация изображений в реальном времени с использованием глубокого обучения было достигнуто используя используя разворачивание глубоких циклов (deep 
loop unfolding) и непосредственный вывод (direct inference). Разворачивание глубоких циклов включает прерывание итераций вариативного генерационного алгоритма как слой конволюционной нейронной сети, и обучение 
полученной сети происходит под постоянным наблюдением. Эта методология показала более простые, точные и эффективные генерации изображений для различных медицинских задач визуализации, таких как визуализация 
магнитного резонанса, компьютерная томография, или интенсивная дифракционная томография. Однако, разворачивание глубоких циклов неприменимо для генерации оптоакустических изображений в реальном времени, так как 
это требует повторения оценки используемой прямой оптоакустической модели (как минимум одна прямая и одна смежная модель оценки для неразделимого блока данных, для примера смотрите уравнение 11 в структуру MoDL), 
которая слишком вычислительно затратна чтобы позволить обработку в реальном времени (для примера с использованием сборки визуализации из этой статьи, одна оценка прямой модели или смежной модели уже занимает 
более 50 мс на графическом процессоре NVIDIA GeForce RTX 3090). В противовес этому, генерация охображений на основе машинного обучения с исползованием непосредственного вывода может поддерживать генерацию 
изображений в реальном времени, так как данный подход не требует оценки оптоакустической модели в процессе генерации. В течении последних лет, несколько вариаций методов непосредственного вывода были 
представлены чтобы или напрямую выдавать высококачественные изображения из записанных сигналов, или накапливать операцию минимизации из итеративной  генерации на основе моделей.

Ключевым вызовом в применении глубокого обучения для генерации оптоакустических изображений это генерация подходящих данных для обучения, то есть входных синограм и соответствующих им контрольных изображений 
оптоакустических начальных давлений. В общем, обучение сети должно опираться на синтезированные данные, так как достоверная информация  о распределении начального давления в биологических тканях экспериментально 
недоступно. Синтез данных включает ручное контрольное распределение начального давления и симулирование соответствующих синограм используя физическую прямую модель процесса вызуализации. Однако, синограммы, 
синтезированные подобным образом, и контрольные изображения только частично отражают реальные параметры экспериментальных данных, следовательно, их использование как входных пар для обучения нейронной сети 
может привести к уменьшению точности генерации для естетвенных данных.

В данной работе мы показываем, что обучене хорошо поставленного оператора генерации облегчает точное обобщение из синтезированных тестовых данных в экспериментальные тестовые данные. Мы достигаем генерации 
оптоакустических изображений в реальном времени для произвольных (экспериментальных) входных данных путем выражения генерации на основе моделей с использованием глубокой нейронной сети. Представленная структура 
глубокого обучения, DeepMB, обучается точному и универсально применимому оператору оптоакустической генерации изображений на основе моделей через обучение на оптоакустических сигналах, синтезированных из 
изображений рельаного мира, при этом используя оптоакустические изображения, сгенерированные с помощью генерации на основе моделей соответствующих сигналов, как достоверные. DeepMB предоставляет практически 
неотличимую по качеству от совершенной визуализации итеративной генерации на основе моделей со скоростью, позволяющей визуализвацию в реальном времени (32 кадра в секунду, 31 мс/изображение, против 30-60 
с/изображение для итеративной генерации на основе моделей). Более того, DeepMB напрямую сравнима с совершенными клиническими МСОТ сканерами, так как оно поддерживает высокую пропускную способность получения 
данных (частота дискретизации: 40 МГц; число приобразователей: 256) и большое разрешение изображений (416x416 пикселей). DeepMB также поддерживает динамическую регулировку параметра скорости звука, что позволяет 
генерировать сфокусированные изображения для множества типов тканей. Мы демонстрируем поизводительность DeepMB как количественно, так и качественно, на разнообразном наборе данных естественных изображений (416 
изображений, 6 участников, 25-19 сканирвоанных частей тела у пациента). С DeepMB, клинические МСОТ могут предоставить отклик в высоком качестве в течении визуализации в реальном времени и таким образом облегчает 
продвинутые изображения динамической визуализации.

> ![](https://sun9-28.userapi.com/c237231/u138836881/docs/d30/e7ec47891042/ezgif-5-f0bd9115e8.gif?extra=PNWH_NRyUs31i7qRBxWJ_kJzXIBoztmhgofIsIpiYIWeULMDUmRP9hyC88eBtgz83-WknJM3O2gaYpIdjFK3kcpcQaaZ_dycr1Xt8ta_GgAD2l9quSwfe2vwI-9uvUsC9tzUzWQQLcIol6UgNF5e8Jymtg)  
> <em> Фрирен спит </em>

#### 2. Результаты
Чтобы подтвердить возможность DeepMB генерировать изображения в реальном времени с возможностью регулировки скорости звука, структура была применена к современному портативному оптоакустическому сканеру
(МСОТ Acuity Echo, iThera, Medical GambH, Мюнхен, Германия) со значениями скоростей звука в диапазоне от 1475 м/с до 1525 м/с с шагом 5 м/с.

##### Процесс разработки DeepMB
На рисунке 1 изображен общий процесс обучения и оценки. DeepMB был обучен, аналогично структуре AUTOMAP, используя входные синограммы, синтезированные из изображений общего вида, чтобы облегчить обучение
беспрестрастному и универсально применимому оператору генераций. Синограммы были сгенерированны путем использования сборника разнообразных изображений реального мира, находящихся в открытом доступе, в качестве 
исходных распределений давления и симулирования на их основе сигналов, записаных с помощью аккустических преобразователей с точной физической моделью рассматриваемого сканера (рисунок 1a и раздел "Методы / Синтез 
синограм для обучения и проверки"). Значения скорости звука для дальнейших симуляций были взяты равномерно случайным образоми (имеется в виду с равномерным распределением) из рассматриваемого диапазона для каждого изображения. Действилельные изображения для 
синтезированных синограм были вычесленны с помощью генераций на основе моделей (рисунок 1с). Рисунок 1d показывает архитекуру глубокой нейронной сети DeepMB, которая получает на вход синограму (или синтетическую, 
или естественную) и значение скорости звука и возвращает итоговое сгенерированное изображение. Основной дизайн основан на архитектуре U-Net, дополненной парой расширений, которые позволяют сети обучаться и 
выражать эффект различных входных значений скорости звука на генерируемое изображение: (1) все сигналы были отображены из входных синограм на область изображения с помощью оператора линейной задержки на основе 
данной на вход величины скорости звука (без обучаемых весов), и (2) входное значение скорости звука (единовременно закодированное и добавленное как дополнительный канал) было передано обучаемым конволюционным 
(конволюция - математический процесс вычисления взвешенного среднего квадратичной матрицы, центром которой проследовательно является каждая точка в изображении) слоям сети. Подробное описание обучения сети дано
в разделе "Методы / Обучение сети". После обучения, приложение DeepMB к клиническим данным было протестировано с разнообразным набором данных естественных синограмм, полученных путем сканирования шести участников 
в не более чем восьми частях тела у каждого (рисунок 1b). Соответствующие достоверные изображения полученных естественных тестовых синограм были получены аналогично тренеровочным данным используя генерацию на 
основе моделей. Вывод DeepMB составил 31 мс на образец на современном видеопроцессоре (NVIDIA GeForce RTX 3090).

![Изображение полного процесса разработки](https://sun9-62.userapi.com/impg/wDTP6sd4DKcW8clCRyYOAmvpQ73nT9lXWzBx2w/0ov_V9psDec.jpg?size=763x405&quality=96&sign=cedda79369589519d83b466667a9c028&type=album)  
<em>
Рисунок 1: Процесс разработки DeepMB. (a) Изображения реального мира, полученные из общественно доступного набора данных, используются чтобы сгенерировать синтетические синограмы путем применения точной 
физической прямой модели сканера. SoS, скорость звука. (b) Естественные синограмы были получены из различных частей тела шести участников. \(c\) Оптоакустические изображения генерируются с помощью итеративной 
реконструкции на основе моделей с целью генерации контрольных изображений для синтетического набора данных (A) или естественного набора данных (B). (d) Обучение сети проведено с использованием синтетических 
данных как набора для тренировки (n = 8000) и проверки (n = 2000) (С), в то время как естественные данные используются как набор тестов (n = 4814) (D). Преобразование доменов сначала применяется к входным 
синограмам с помощью операции задержки чтобы отобразить значения из выборки времени на область изображения. Скорость звука определяется единовременно и добавляется как отдельные каналы (отображено как символ "⧺"). 
Конволюционная нейронная сеть U-Net впоследствии применяется к стеку каналов чтобы регрессировать конечное изображение. Различие вычисляется между выводом сети и соответствующим контрольным изображением (смотрите 
раздел "Методы / Обучение сети" для дальнейшей информации касательно обечения сети).
</em>

> Эти разделы из методов я перевел, так как на них были ссылки в разделе процесса разработки

#### 4. Методы

##### Синтез синограм для обучения и проверки
Для обучения и проверки, оптоакустические синограмы были синтезированы с помощью точной физической прямой модели процесса визуализации, который включает в себя полную импульсную характеристику системы, 
использующцю величину скорости звука как параметр, взятый равномерно случайным образом из диапазона 1475-1525 м/с с шагом 5 м/c. Изображения реального мира, использованные в качестве начального распределения 
давления для дальнейшей симуляции, были случайно выбираны из общественно доступного набора данных PASCAL Visual Object Classes Challenge 2012 (VOC2012), и преобразованы в одноканальные черно-белые изображения 
с разрешением 416 на 416 пикселей. После применения прямой модели, каждая синтезированная синограма была масштабирована на коэффициент, выбранный равномерно случайным образом из диапазона 0-450 для лучшего 
соответствия дисперсии, наблюдаемой  на синограммах в естественных условиях.

##### Обучение сети
Сеть DeepMB была реализована на языке программирования Python с исползованием PyTorch. Она была обучена &mdash; или на синтезированных или на естественных данных &mdash; в течение 300 поколений используя 
[стохастический градиентный спуск](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA) 
с размером партии равном 4, скорости обучения равной 0.01, импульсом равном 0.99, и коэффициентом затухания скорости обучения равном 0.99. Потеря сети была вычислена как среднее квадратическое откланение между 
выходным изображением и контрольным изображением. Итоговая модель была выбрана на основе минимальной потери на проверочном наборе данных, и наконец скомпилирована в ONNX модел для ускорения.

Для облегчения обучения, все входные синогрмы были масштабированны на $K=450^{-1}$ чтобы убедиться что ни одно значение не выйдет из диапазона \[-1, 1\]. Идентичный коэффициент масштабирования также был применен 
ко всем целевым изображениям. Более того, квадратный корень был применен ко всем целевым контрольным изображениям, используемым в процессе обучения и проверки, чтобы редуцировать выходные значения сети и 
ограничить влияние пикселей с высокой интенсивностью в процессе вычисления потери. Когда обученная сеть применяется к естественным данным, предполагаемые изображения (имеется в виду те, что выдала нейронка),
сначала были возведены в квадрат и масштабированы на $K^{-1}$, чтобы отменить операции обработки.

В процессе обучения на синтетических данных для сборки стандартной модели DeepMB мы использовали 8000 синограм для обучающей части и 2000 синограм для проверочной части. Альтернативный сценарий, включавший 
обучение на естественных данных чтобы собрать модель DeepMB$_{in\ vivo}$, был отброшен как пояснено далее: было проведено шесть различных перестановок с разделением участников 4/1/1 между частями обучения, 
проверки, и тестирования, соответственно каждый участник принимал участие в частях проверки и тестирования только один раз.

Сеть DeepMB основана на архитектуре U-Net с глубиной в 5 слоев и шириной 64 характеристик. Чтобы постепено сократить число каналов данных с 267 (включая 256 элементов преобразования и 11 возможных значений 
сокрости звука) до 64, три двумерных конволюционных слоя с 208, 160 и 112 характеристиками соответственно, были добавлены перед U-Net. Все размеры ядра и отступов были (3, 3) и (1, 1) соответственно. Были 
учтены погрешности, в качестве итоговыой активации использовалась функция модуля.
